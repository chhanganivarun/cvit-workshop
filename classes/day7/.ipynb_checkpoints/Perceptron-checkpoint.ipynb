{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NiLPMhPgYFa"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9CxCComgihL"
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0k4a9Qbe6p1"
   },
   "source": [
    "In this experiment, we will use the CIFAR-10 dataset. It consists of 60,000 32x32 colour images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "**The code returns the contents of each data file as a dictionary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DL8erXHHe6p2"
   },
   "source": [
    "There are 8 pickled (To know more about pickle refer **Python_Pickle_Introduction** notebook )files in the CIFAR-10 directory.\n",
    "\n",
    "    1. batches.meta\n",
    "\n",
    "    2. data_batch_1\n",
    "\n",
    "    3. data_batch_2\t\n",
    "\n",
    "    4. data_batch_3\n",
    "\n",
    "    5. data_batch_4\t\n",
    "\n",
    "    6. data_batch_5\n",
    "\n",
    "    7. readme.html\n",
    "\n",
    "    8. test_batch\n",
    "\n",
    "Getting into details of this dataset:\n",
    "\n",
    "\n",
    "**data** : A 50,000x3072 numpy array of unsigned integers. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "**labels** : A list of 50,000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecPwLon_e6p4"
   },
   "source": [
    "### DataSource\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9Mdrhr8e6p4"
   },
   "source": [
    "#### Perceptron\n",
    "\n",
    "\n",
    "A perceptron has one or more inputs, a bias, an activation function, and a single output. The perceptron receives inputs, multiplies them by some weight, and then passes them into an activation function to produce an output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYSSCRSwfOBb"
   },
   "source": [
    "### Setup Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "8jG97PJImsd8"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to complete the setup for this Notebook\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week3/Exp3/AIML_DS_CIFAR-10_STD.zip\")\n",
    "ipython.magic(\"sx unzip AIML_DS_CIFAR-10_STD.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-60ux8L8gPYb"
   },
   "source": [
    "### Expected time to complete experiment is 60 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cmlHxf-e6p7"
   },
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import itertools\n",
    "import operator\n",
    "import random\n",
    "import collections\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_RfJjpFG0kp"
   },
   "source": [
    "#### Function to unpickle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4qKDf-ee6qA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict_1 = pickle.load(fo, encoding='Latin1')\n",
    "    return dict_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "706Q4tnBe6qE"
   },
   "source": [
    "### Visualizing the images in CIFAR-10 Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6119xCxOAbF"
   },
   "source": [
    "When you pass a pickled file to the get_data function it returns features, labels, file names, list of classes of the corresponding file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1_yJnrxJEcr"
   },
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    dict_1 = unpickle(file)\n",
    "    X = np.asarray(dict_1['data']).astype(\"uint8\")\n",
    "    Y = np.asarray(dict_1['labels'])\n",
    "    names = np.asarray(dict_1['filenames'])\n",
    "    list_class=(unpickle(\"AIML_DS_CIFAR-10_STD/batches.meta\")['label_names'])\n",
    "    return X,Y,names,list_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONBuR6rLe6qG"
   },
   "outputs": [],
   "source": [
    "# Function to visualize the data\n",
    "def visualize_image(X, Y, names, image_id,size=(5,5)):\n",
    "    rgb = X[image_id,:]\n",
    "    plt.figure(figsize = size)\n",
    "    img = rgb.reshape(3, 32, 32).transpose([1, 2, 0])\n",
    "    print(img.shape)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(img)\n",
    "    plt.title(names[image_id])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omWvcXvae6qL"
   },
   "outputs": [],
   "source": [
    "# Read 10000 images -- from batch 3\n",
    "X, Y, names, classes = get_data(\"AIML_DS_CIFAR-10_STD/data_batch_3\")\n",
    "# Display the 10th image\n",
    "pick = 10\n",
    "print(\"Class =\",classes[Y[pick]])\n",
    "visualize_image(X, Y, names, pick,size=(0.3,0.3)) # output image would be a blured image\n",
    "visualize_image(X, Y, names, pick,size=(3,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCjvhMpyIgyf"
   },
   "source": [
    "**NOTE: **\n",
    "\n",
    "**The images you see above are pixelated and hence they are  blur.** (Pixelation happens when you display a low resolution of an image on a larger canvas (such a large screen), where each pixel ends up being displayed as an image. You could read more about it on https://whatis.techtarget.com/definition/pixelation ).  This however does not affect the prediction of your machine learning algorithm, for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAy2u-Ffe6qX"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "def predict(train_features,test_features,train_labels): \n",
    "    clf = Perceptron(tol=1e-3, random_state=0)\n",
    "    # Fitting the data into the model\n",
    "    clf.fit(train_features, train_labels)\n",
    "    # Predicting the labels for test data\n",
    "    predicted_values = clf.predict(test_features)\n",
    "    return predicted_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S03AOIJW6Elf"
   },
   "source": [
    "**Let us define a function to calculate accuracy score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOKjt1Lpe6qm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def calc_accuracy(train_features,test_features,train_labels,test_labels):\n",
    "    # Calling predict function to get the predicted labels of test data\n",
    "    pred = predict(train_features,test_features,train_labels)\n",
    "    return accuracy_score(pred, test_labels)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFpkHmA76z46"
   },
   "source": [
    "**Now let us unpickle the data and labels from CIFAR-10 dataset and divide them into training and testing sets..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsRkIdoCe6qq"
   },
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_labels = []\n",
    "# Read all training features and labels\n",
    "for j in \"12345\": \n",
    "    batch_file = 'AIML_DS_CIFAR-10_STD/data_batch_'+ j\n",
    "    x_train, y_train, names_train, classes_train = get_data(batch_file)\n",
    "    train_features.extend(x_train)\n",
    "    train_labels.extend(y_train)\n",
    "\n",
    "train_features = np.asarray(train_features)\n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "# Read all test features and labels\n",
    "test_features, test_labels, names_test, classes_test = get_data(\"AIML_DS_CIFAR-10_STD/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTS853um7cOl"
   },
   "outputs": [],
   "source": [
    "test_labels.shape, train_labels.shape, test_features.shape, train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMSkyevFwviz"
   },
   "outputs": [],
   "source": [
    "# Function to extract the classes\n",
    "def extract_2classes(class0, class1, X, Y):\n",
    "    # Select class #0\n",
    "    X_0 = X[Y == class0]\n",
    "    Y_0 = Y[Y == class0]\n",
    "    # Select class #1\n",
    "    X_1 = X[Y == class1]\n",
    "    Y_1 = Y[Y == class1]\n",
    "    # Join the two classes to make the set\n",
    "    X_2classes = np.vstack((X_0, X_1))\n",
    "    Y_2classes = np.append(Y_0, Y_1)\n",
    "    return X_2classes, Y_2classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGAVzdP8wx58"
   },
   "outputs": [],
   "source": [
    "# Select classes #5 and #7\n",
    "X_train_2classes, Y_train_2classes = extract_2classes(5, 7, train_features, train_labels)\n",
    "X_test_2classes, Y_test_2classes = extract_2classes(5, 7,test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4h3fqmuEDp0"
   },
   "outputs": [],
   "source": [
    "calc_accuracy(X_train_2classes,X_test_2classes,Y_train_2classes,Y_test_2classes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
